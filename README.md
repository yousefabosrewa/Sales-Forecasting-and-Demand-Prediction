Sales Demand Forecasting MLOps ProjectProject OverviewThis project implements a robust Sales Demand Forecasting solution leveraging MLOps principles to ensure reproducibility, scalability, and efficient deployment. The primary objective is to accurately predict future sales revenue at both transactional and aggregated daily levels, providing valuable insights for business planning, inventory management, and marketing strategies.The project utilizes a modular architecture, separating concerns into distinct stages: data preprocessing, feature engineering, model training, model serving via a REST API, and a user-friendly web interface built with Streamlit. MLflow is integrated for experiment tracking and model management, while DVC is used for data and pipeline versioning, ensuring reproducibility across different environments.FeaturesData Preprocessing: Handles raw data loading, cleaning, outlier treatment, and initial feature transformations (e.g., one-hot encoding, scaling).Feature Engineering: Creates relevant time-series features (e.g., day of week, month, quarter, holidays) and potentially lag/rolling window features.Multiple Model Training: Trains various forecasting models, including:Transactional Models (e.g., Random Forest, XGBoost) for predicting individual transaction revenue.Time-Series Model (e.g., SARIMA) for predicting aggregated daily revenue trends.MLflow Experiment Tracking: Logs training parameters, metrics (MAE, RMSE, R2), and model artifacts for comparison and management.DVC Versioning: Manages versions of data, models, and the entire pipeline, enabling reproducibility and collaboration.Flask REST API: Provides endpoints for real-time single transaction predictions, batch predictions via CSV upload, and time-series forecasts.Streamlit Web Application: Offers an interactive user interface for data visualization, making single/batch predictions, and viewing time-series forecasts.Model Monitoring (Basic): Includes a script to check model performance against a baseline (expandable for drift detection, etc.).Containerization (Implied/Planned): Designed with containerization in mind for consistent deployment environments.Project Structure.
├── data/
│   ├── processed/             # Processed data, daily aggregated data, monitoring reports
│   └── synthetic/             # Raw synthetic data
├── models_initial/            # Trained models and preprocessor components
├── src/
│   ├── api/                   # Flask API code (main.py, model_loader.py)
│   ├── data_preprocessing.py  # Data preprocessing logic
│   ├── feature_engineering.py # Feature engineering logic
│   ├── evaluate.py            # Model evaluation logic
│   ├── monitor.py             # Model monitoring script
│   ├── predict_utils.py       # Prediction utility functions
│   ├── streamlit_app/         # Streamlit application code (app.py)
│   └── train.py               # Model training pipeline
├── .dvcignore                 # DVC ignore file
├── .gitignore                 # Git ignore file
├── dvc.yaml                   # DVC pipeline definition
├── MLproject                  # MLflow project definition
├── requirements.txt           # Python dependencies
├── conda.yaml                 # Conda environment definition (optional)
└── README.md                  # Project README (this file)
SetupTo set up and run this project locally, follow these steps:PrerequisitesPython 3.8+GitConda or venv (for environment management)Docker (optional, for containerized deployment)1. Clone the Repositorygit clone <repository_url>
cd sales-demand-forecasting-mlops
2. Set up Python EnvironmentIt is highly recommended to use a virtual environment.Using Conda:conda env create -f conda.yaml
conda activate sales-forecasting-mlops
Using venv:python -m venv .venv
source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`
pip install -r requirements.txt
3. Install DVCIf you don't have DVC installed globally, you can install it in your virtual environment:pip install dvc[all] # Installs DVC with support for various remotes
4. Initialize DVC and Reproduce the PipelineInitialize DVC in the project root and run the pipeline defined in dvc.yaml. This will download/process data, engineer features, train models, and save artifacts.dvc init --no-scm # Initialize DVC without linking to Git remote initially
dvc repro
This command executes the preprocess and train stages defined in dvc.yaml. The processed data, preprocessor, trained models (RF, XGB, SARIMA), and daily aggregated data will be generated and versioned by DVC.5. Set up MLflow (Optional but Recommended)To view MLflow tracking logs, navigate to the project root and run:mlflow ui
This will start the MLflow tracking UI, typically accessible at http://localhost:5000.UsageRunning the Flask APIThe Flask API serves the trained models for predictions. Using Waitress is recommended for production or Windows environments.waitress-serve --listen=0.0.0.0:5001 src.api.main:app
The API will be available at http://localhost:5001.Running the Streamlit AppThe Streamlit app provides a user interface to interact with the project.streamlit run src/streamlit_app/app.py
The app will open in your web browser, typically at http://localhost:8501. Ensure the Flask API is running before using the prediction functionalities in the app.Using the API EndpointsOnce the Flask API is running, you can interact with it directly using tools like curl, Postman, or by making requests from your code.POST /predict: Single transaction prediction. Expects JSON input.POST /predict_batch_csv: Batch prediction. Expects CSV file upload.GET /status: Check API status and loaded models.POST /forecast_sarima: Time-series forecast. Expects JSON input with start_date and end_date.Refer to src/api/main.py for detailed endpoint definitions and expected data formats.Running the Monitoring ScriptThe monitoring script checks the performance of the deployed model against a baseline.python src/monitor.py --new_data_path data/processed/new_data_sample.csv --model_path models_initial/best_random_forest_revenue_model.pkl --preprocessor_path models_initial/preprocessor.pkl --baseline_metrics_path data/processed/baseline_metrics.json --report_output_dir data/processed/performance_reports --alert_log_path data/processed/monitoring_alerts.log
Adjust the parameters as needed for your new data and desired output locations.MLOps ComponentsMLflowMLflow is used throughout the training process (src/train.py) to:Track parameters used for each model run (hyperparameters, data split dates).Log evaluation metrics (MAE, RMSE, R2) on the test set.Store model artifacts (the trained .pkl files).Organize runs into experiments for easy comparison.Run mlflow ui in the project root to explore the experiment tracking results.DVCDVC is integrated to manage the lifecycle of data and models:Data Versioning: dvc add is used (implicitly by dvc repro based on dvc.yaml) to version the raw and processed data files (.dvc files and cache).Pipeline Versioning: dvc.yaml defines the sequence of steps (preprocess, train) and their dependencies, making the entire pipeline reproducible with dvc repro.Model Versioning: Trained models are treated as data artifacts and versioned by DVC.This allows for tracking changes to data and code that affect model outputs and facilitates switching between different versions of the pipeline.Future EnhancementsAutomated Monitoring: Implement scheduled monitoring checks and integrate with alerting systems (e.g., email, Slack).CI/CD Pipeline: Set up a CI/CD pipeline to automate testing, training, and deployment upon code changes.Containerization: Create Docker images for the Flask API and Streamlit app for easier deployment.Cloud Deployment: Deploy the API and Streamlit app to a cloud platform (AWS, GCP, Azure).Advanced Monitoring: Implement data drift and model drift detection.Model Registry: Utilize MLflow Model Registry for better model versioning and staging.Hyperparameter Tuning: Integrate hyperparameter tuning frameworks (e.g., Optuna, Hyperopt) with MLflow.More Sophisticated Models: Explore deep learning models or ensemble methods for forecasting.Unit and Integration Tests: Add comprehensive tests for code modules and API endpoints.LicenseThis project is licensed under the MIT License.ContactFor questions or feedback, please open an issue on the GitHub repository.