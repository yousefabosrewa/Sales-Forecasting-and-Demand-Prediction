{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xikbbBlfYWjv"
   },
   "source": [
    "Dataset Desription:\n",
    "\n",
    "**Transaction Data**\n",
    "\n",
    "Transaction_ID: Unique identifier for each transaction.\n",
    "\n",
    "Customer_ID: Unique identifier for the customer associated with the transaction.\n",
    "\n",
    "Product_ID: Unique identifier for the product purchased in the transaction.\n",
    "\n",
    "Transaction_Date: The date when the transaction occurred.\n",
    "\n",
    "**Product Information**\n",
    "\n",
    "Category: The category to which the product belongs (e.g., Electronics, Clothing).\n",
    "\n",
    "Units_Sold: The quantity of the product sold in the transaction.\n",
    "\n",
    "Discount_Applied: The discount percentage applied to the product during the transaction.\n",
    "\n",
    "Revenue: Total revenue generated from the transaction, calculated as Price x Units Sold x (1 - Discount).\n",
    "\n",
    "**Customer Demographics**\n",
    "\n",
    "Customer_ID: Unique identifier for each customer (repeated for easier reference).\n",
    "\n",
    "Age: Age of the customer.\n",
    "\n",
    "Gender: Gender of the customer (Male, Female, Other).\n",
    "\n",
    "Location: Geographical location of the customer.\n",
    "\n",
    "Customer_Lifetime_Value: Estimated lifetime value of the customer to the e-commerce platform.\n",
    "\n",
    "**Advertising Metrics**\n",
    "\n",
    "Clicks: Number of ad clicks associated with the product during the time of the transaction.\n",
    "\n",
    "Impressions: Number of ad impressions served during the campaign.\n",
    "\n",
    "Conversion_Rate: Calculated as Clicks / Impressions, representing the percentage of impressions that resulted in clicks.\n",
    "\n",
    "Ad_CTR: Click-through rate (CTR) for the advertisement, representing the effectiveness of the ad campaign.\n",
    "\n",
    "Ad_CPC: Cost-per-click for the advertisement.\n",
    "\n",
    "Ad_Spend: Total advertising spend for the product, calculated as Ad_CTR x Ad_CPC x 1000.\n",
    "\n",
    "**Seasonal and Regional Information**\n",
    "\n",
    "Region: The geographical region where the transaction occurred (e.g., North America, Europe, Asia).\n",
    "\n",
    "Seasonality Effects: Implied through patterns in transaction dates and revenue, reflecting holiday promotions and season-based purchasing trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMmyI0--W6z4"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mdnMCPSXum8"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df=pd.read_csv('../Data/synthetic_ecommerce_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "IrXQKEsNX75N",
    "outputId": "39658e09-43b4-4e12-e79d-8364cce49d11"
   },
   "outputs": [],
   "source": [
    "# Checking the first five rows to ensure the data is loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOaRFt1QYFRk",
    "outputId": "44f50329-9317-4a81-f911-1809636343f8"
   },
   "outputs": [],
   "source": [
    "# Check how manys rows and cols\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odErs3vaZcAX",
    "outputId": "e6b2089f-e949-4e19-87e6-178ba59ee3c3"
   },
   "outputs": [],
   "source": [
    "# Check the nulls, and the data types of the cols\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6mHa809ZlIU"
   },
   "source": [
    "No nulls and these cols (Transaction_ID,\n",
    "Customer_ID, Product_ID) are trivial need to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgsY74rSZ61E"
   },
   "outputs": [],
   "source": [
    "df.drop(['Transaction_ID', 'Customer_ID', 'Product_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDeZpdjmZ_uc",
    "outputId": "7b48399a-fd8d-46d4-c7b0-69b5a0ce0248"
   },
   "outputs": [],
   "source": [
    "# Check the duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ewRC71hZalnw",
    "outputId": "8d387c1b-1e46-4c66-b908-ea8ebb15fdd0"
   },
   "outputs": [],
   "source": [
    "# Check some statistical info about the dataset to have an overview if there are some outliers and the dataset distribution\n",
    "# Include all cols even the categorical (nominal) ones\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQPmLH-7goDH"
   },
   "outputs": [],
   "source": [
    "df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1u0DYC_bYeO"
   },
   "source": [
    "Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "nukgqltTbadg",
    "outputId": "4e225ec5-607a-4a76-dbe6-7c444f30c4e7"
   },
   "outputs": [],
   "source": [
    "# Create a pie chart of the Category column\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "counts = df[\"Category\"].value_counts()\n",
    "plt.pie(counts, labels=counts.index, autopct='%1.0f%%')\n",
    "plt.title('Category Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqceaPmhbpj7"
   },
   "source": [
    "Almost balanced Category distribution among these five options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "28w0XVcbb52G",
    "outputId": "9156154b-fb2f-4873-d511-0271e151d592"
   },
   "outputs": [],
   "source": [
    "# Create a pie chart of the Region column\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "counts = df[\"Region\"].value_counts()\n",
    "plt.pie(counts, labels=counts.index, autopct='%1.0f%%')\n",
    "plt.title('Region Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QRrvF37b_1u"
   },
   "source": [
    "The distribution among the regions is perfectly balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "COgaxQg2cTRh",
    "outputId": "d4ad0dba-d6dd-4839-c5ef-3537b1c62186"
   },
   "outputs": [],
   "source": [
    "# Numerical Cols Distribution\n",
    "cols=np.array(df.select_dtypes(include=['int64', 'float64']).columns)\n",
    "for col in cols:\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY3vglSqgExI"
   },
   "source": [
    "Some of the columns (Ad_Spend, Revenue, Conversion_Rate) are exponentially distributed --> log scaling\n",
    "\n",
    "Others (Ad_CPC, Ad_CTR, Clicks, Impressions, Discount_Applied) are uniformly distributed --> min-max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1w2dPvMh65W"
   },
   "source": [
    "Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "TjT2SpLcguY5",
    "outputId": "983a9453-c4b4-4ed6-9c13-7373203da557"
   },
   "outputs": [],
   "source": [
    "# Revenue over time (aggregated Monthly)\n",
    "monthly_revenue = df.groupby(pd.Grouper(key='Transaction_Date', freq='M'))['Revenue'].sum()\n",
    "monthly_revenue.plot(title='Monthly Revenue Trend', figsize=(12,6))\n",
    "plt.ylabel('Revenue')\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu150PkYhfYO"
   },
   "source": [
    "November is the month with the highest revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "ykDpVQZzgsrN",
    "outputId": "bf7f1722-32a3-46e5-d2e4-1654add16690"
   },
   "outputs": [],
   "source": [
    "# Units Sold over time\n",
    "weekly_units = df.groupby(pd.Grouper(key='Transaction_Date', freq='W-SUN'))['Units_Sold'].sum()\n",
    "weekly_units.plot(title='Weekly Units Sold Trend', figsize=(12,6))\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9fLayGbhsah"
   },
   "source": [
    "The highest no of units sold is also in November which does make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_yuJZAWshx1V",
    "outputId": "ba41985d-0aec-479f-e0d2-4b0172cdbc5e"
   },
   "outputs": [],
   "source": [
    "# Revenue by Category\n",
    "category_revenue = df.groupby('Category')['Revenue'].sum().sort_values()\n",
    "category_revenue.plot(kind='barh', title='Revenue by Category')\n",
    "plt.xlabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr06FDjZiCx4"
   },
   "source": [
    "Almost the same revenue across the categories (Electronics is higher a little bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "6spXRjykiMj3",
    "outputId": "2a6306aa-6e26-4e8b-9ad5-4c2896888f59"
   },
   "outputs": [],
   "source": [
    "# Revenue by Region\n",
    "region_rev = df.groupby('Region')['Revenue'].sum()\n",
    "region_rev.plot(kind='bar', title='Revenue by Region', color='teal')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBBlSwrti9ue"
   },
   "source": [
    "The revenue is the same across the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "J0BFS53-jFr9",
    "outputId": "26dc4f44-0509-49b4-cbf3-26c83f3a0b66"
   },
   "outputs": [],
   "source": [
    "# Units Sold by Region and Season (example seasonal grouping)\n",
    "df['Month'] = df['Transaction_Date'].dt.month\n",
    "sns.barplot(data=df, x='Region', y='Units_Sold', hue='Month')\n",
    "plt.title('Units Sold by Region and Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQ41ERf_jsrj"
   },
   "source": [
    "The highest no of units sold is at North America in October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "A6MVg7e8kJfr",
    "outputId": "57cf6b46-a90e-430a-ba89-e78c98a5bfa5"
   },
   "outputs": [],
   "source": [
    "# Ad Spend vs Revenue\n",
    "sns.scatterplot(data=df, x='Ad_Spend', y='Revenue')\n",
    "plt.title('Ad Spend vs Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1S195afkONP"
   },
   "source": [
    "This shows the advertising effect on the revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "EcChOIXVkRaZ",
    "outputId": "3372068d-0b4d-4d65-95f3-3ee1dfe4a8ad"
   },
   "outputs": [],
   "source": [
    "# Conversion Rate vs Revenue\n",
    "sns.scatterplot(data=df, x='Conversion_Rate', y='Revenue')\n",
    "plt.title('Conversion Rate vs Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "55a-k8ttkbME",
    "outputId": "3a81a86d-ae9f-4528-a06b-6a91863a6327"
   },
   "outputs": [],
   "source": [
    "# Clicks vs Units Sold\n",
    "sns.scatterplot(data=df, x='Clicks', y='Units_Sold')\n",
    "plt.title('Ad Clicks vs Units Sold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Cw4i2AyKkloj",
    "outputId": "b13e686f-5c74-4f12-d593-89c020bcde56"
   },
   "outputs": [],
   "source": [
    "# Heatmap of Revenue by Day of Week and Month\n",
    "df['DayOfWeek'] = df['Transaction_Date'].dt.day_name()\n",
    "heatmap_data = df.pivot_table(index='DayOfWeek', columns='Month', values='Revenue', aggfunc='sum')\n",
    "sns.heatmap(heatmap_data, cmap='YlGnBu')\n",
    "plt.title('Revenue Heatmap (Day vs Month)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FybfKY4zkrh9"
   },
   "source": [
    "October and November has highest correlations as demonstrated from the other analysis in addition to having the hghest correlation on Friday (which does make sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PgZyftWmpxm"
   },
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vNK-oEdyk_Ow",
    "outputId": "60da8526-2f2b-4e12-f7e3-1f96ecd133b7"
   },
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "sns.heatmap(df[numerical_cols].corr(), cmap=\"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSq0eU6_m-u1"
   },
   "source": [
    "Check what is not too correlated with the target col (units_sold) and leave it while checking the most correlated features (>0.8) to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qB0xEBe1m1Yn",
    "outputId": "c3f8c127-52b2-4308-c63c-50182e2b73d4"
   },
   "outputs": [],
   "source": [
    "columns = df.select_dtypes(include=np.number)\n",
    "correlation_matrix = columns.corr()\n",
    "# Identify columns to drop\n",
    "to_drop = set()\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "        # Check correlation threshold\n",
    "        if correlation_matrix.iloc[i, j] > 0.8:\n",
    "            col_to_drop = correlation_matrix.columns[j]\n",
    "            to_drop.add(col_to_drop)\n",
    "\n",
    "# Drop the highly correlated columns\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "print(\"Dropped columns:\", to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAJuvge-nUbL"
   },
   "source": [
    "Rounding the float cols to avoid noise effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFboHyhcnXii"
   },
   "outputs": [],
   "source": [
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "df[float_cols] = df[float_cols].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-X-V8-TnevF"
   },
   "source": [
    "Processing Categorical Cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KlheOjPnhUM"
   },
   "source": [
    "One hot encoding: https://www.geeksforgeeks.org/ml-one-hot-encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odubC91snhxB"
   },
   "outputs": [],
   "source": [
    "# Use pd.get_dummies() to one-hot encode the categorical columns\n",
    "categorical_columns = ['Category', 'Region']\n",
    "df_pandas_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Get feature names and make them unique by prefixing with category\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded,\n",
    "                            columns=feature_names)\n",
    "\n",
    "# Reset index of both DataFrames before concatenating\n",
    "df = pd.concat([df.drop(categorical_columns, axis=1).reset_index(drop=True),\n",
    "                                one_hot_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cHFY6DQn4eE"
   },
   "source": [
    "Outliers Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyTsdD2bn6H-"
   },
   "source": [
    "https://byjus.com/maths/interquartile-range/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVGTu6u_n6ga"
   },
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "for column in numeric_cols:\n",
    "\n",
    "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "    q1, q3 = np.percentile(df[column], [25, 75])\n",
    "\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Set the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Replace outliers with the median value (Q2)\n",
    "    df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), np.median(df[column]), df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80kXX2QUoCpf"
   },
   "source": [
    "Scaling Based on the cols distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lkKq8hroGR8"
   },
   "outputs": [],
   "source": [
    "# Define column groups\n",
    "log_cols = ['Ad_Spend', 'Revenue', 'Conversion_Rate']\n",
    "minmax_cols = ['Ad_CPC', 'Ad_CTR', 'Clicks', 'Impressions', 'Discount_Applied']\n",
    "\n",
    "# Make a copy of the original DataFrame\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# Apply log1p transformation to log-distributed columns\n",
    "df_transformed[log_cols] = df_transformed[log_cols].apply(np.log1p)\n",
    "\n",
    "# Apply Min-Max scaling to uniform columns\n",
    "scaler = MinMaxScaler()\n",
    "df_transformed[minmax_cols] = scaler.fit_transform(df_transformed[minmax_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfe35eaCpkkp"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "df_transformed.to_csv('../Data/PreparedSalesData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Milestone 3<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your cleaned and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure chronological order and set date as index\n",
    "df = pd.read_csv('../Data/PreparedSalesData.csv')\n",
    "df = df.sort_values('Transaction_Date')\n",
    "df.set_index('Transaction_Date', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the target variable (Revenue) over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['Revenue'])\n",
    "plt.title('Revenue Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering: create lag and rolling features for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df.index.month\n",
    "df['dayofweek'] = df.index.dayofweek\n",
    "df['weekofyear'] = df.index.isocalendar().week.astype(int)\n",
    "df['quarter'] = df.index.quarter\n",
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Lag features\n",
    "for lag in [1, 7, 14, 30]:\n",
    "    df[f'revenue_lag_{lag}'] = df['Revenue'].shift(lag)\n",
    "    df[f'units_lag_{lag}'] = df['Units_Sold'].shift(lag)\n",
    "# Rolling window features\n",
    "for window in [7, 14, 30]:\n",
    "    df[f'revenue_rollmean_{window}'] = df['Revenue'].rolling(window).mean()\n",
    "    df[f'units_rollmean_{window}'] = df['Units_Sold'].rolling(window).mean()\n",
    "\n",
    "# Example: Holiday flag (Egyptian holidays, can be extended)\n",
    "holidays = pd.to_datetime([\n",
    "    '2024-04-10',  # Eid al-Fitr (example)\n",
    "    '2024-06-16',  # Eid al-Adha (example)\n",
    "])\n",
    "df['is_holiday'] = df.index.isin(holidays).astype(int)\n",
    "\n",
    "# Example: Season\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]: return 'winter'\n",
    "    if month in [3, 4, 5]: return 'spring'\n",
    "    if month in [6, 7, 8]: return 'summer'\n",
    "    if month in [9, 10, 11]: return 'autumn'\n",
    "df['season'] = df['month'].apply(get_season)\n",
    "df = pd.get_dummies(df, columns=['season'], drop_first=True)\n",
    "\n",
    "# Drop NA from lag/rolling\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split (last 6 months as test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = df.index.max() - pd.DateOffset(months=6)\n",
    "train = df[df.index <= split_date]\n",
    "test = df[df.index > split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    'Units_Sold', 'Discount_Applied', 'Clicks', 'Impressions', 'Conversion_Rate',\n",
    "    'Ad_CTR', 'Ad_CPC', 'Ad_Spend', 'month', 'dayofweek', 'weekofyear', 'quarter', 'is_weekend', 'is_holiday',\n",
    "    'Category_Books', 'Category_Clothing', 'Category_Electronics', 'Category_Home Appliances', 'Category_Toys',\n",
    "    'Region_Asia', 'Region_Europe', 'Region_North America'\n",
    "]\n",
    "lag_roll_features = [col for col in df.columns if 'lag' in col or 'rollmean' in col]\n",
    "season_features = [col for col in df.columns if col.startswith('season_')]\n",
    "features = base_features + lag_roll_features + season_features\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train['Revenue']\n",
    "X_test = test[features]\n",
    "y_test = test['Revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_forecast = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 : XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_forecast = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 : SARIMA (Statistical Time Series Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA can capture trend and seasonality\n",
    "sarima_order = (1, 1, 1)  # (p,d,q)\n",
    "seasonal_order = (1, 1, 1, 12)  # (P,D,Q,s)\n",
    "\n",
    "sarima_model = SARIMAX(train['Revenue'],\n",
    "                        order=sarima_order,\n",
    "                        seasonal_order=seasonal_order,\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "sarima_results = sarima_model.fit(disp=False)\n",
    "\n",
    "# Forecast for the test period using integer indices\n",
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "\n",
    "sarima_pred = sarima_results.get_prediction(start=start, end=end, dynamic=False)\n",
    "sarima_forecast = sarima_pred.predicted_mean\n",
    "\n",
    "# Optional: Assign the test dates to the forecast for plotting\n",
    "sarima_forecast.index = test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                            param_grid,\n",
    "                            cv=tscv,\n",
    "                            scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf_forecast = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"  MAE:  {mae:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  R2:   {r2:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "    return {'model': model_name, 'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "results.append(evaluate(y_test, rf_forecast, \"Random Forest\"))\n",
    "results.append(evaluate(y_test, xgb_forecast, \"XGBoost\"))\n",
    "results.append(evaluate(y_test, best_rf_forecast, \"Best Random Forest\"))\n",
    "results.append(evaluate(y_test, sarima_forecast, \"SARIMA\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis by category and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in ['Category_Books', 'Category_Clothing', 'Category_Electronics', 'Category_Home Appliances', 'Category_Toys']:\n",
    "    mask = test[group] == 1\n",
    "    if mask.sum() > 0:\n",
    "        print(f\"Error for {group}:\")\n",
    "        evaluate(y_test[mask], best_rf_forecast[mask], f\"Best RF ({group})\")\n",
    "\n",
    "for region in ['Region_Asia', 'Region_Europe', 'Region_North America']:\n",
    "    mask = test[region] == 1\n",
    "    if mask.sum() > 0:\n",
    "        print(f\"Error for {region}:\")\n",
    "        evaluate(y_test[mask], best_rf_forecast[mask], f\"Best RF ({region})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Analysis (for best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - best_rf_forecast\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals of Best Random Forest Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(train.index, train['Revenue'], label='Train')\n",
    "plt.plot(test.index, y_test, label='Actual Test')\n",
    "plt.plot(test.index, best_rf_forecast, label='Best RF Forecast')\n",
    "plt.plot(test.index, xgb_forecast, label='XGBoost Forecast', alpha=0.7)\n",
    "plt.plot(test.index, sarima_forecast, label='SARIMA Forecast')\n",
    "plt.legend()\n",
    "plt.title('Revenue Forecasting: Actual vs. Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(best_rf, 'best_random_forest_revenue_model.pkl')\n",
    "joblib.dump(xgb_model, 'xgboost_revenue_model.pkl') "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
